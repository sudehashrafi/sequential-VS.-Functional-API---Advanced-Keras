{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Coursera - Deep Learning with Keras and Tensorflow\n",
        "### Module 1"
      ],
      "metadata": {
        "id": "MN7Ce99ayNIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential API VS. Functional API\n"
      ],
      "metadata": {
        "id": "Bw9ER0S4yabg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential"
      ],
      "metadata": {
        "id": "Nkgm08_tymUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "wzCutLnGyrv5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOf_gYQfyFkw"
      },
      "outputs": [],
      "source": [
        "from Tensorflow.keras.models import Sequential\n",
        "from Tensorflow.kersas.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sequential model\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(784,)),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "PBNDvTlmyJXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "42Qk6rEyyJaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functional"
      ],
      "metadata": {
        "id": "QXVQwouozORp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense"
      ],
      "metadata": {
        "id": "0A4gAq3LyJdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input\n",
        "inputs = Input(shape=(784,))"
      ],
      "metadata": {
        "id": "OHnR0qHUyJgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define layers\n",
        "x = Dense(64, activation='relu')(inputs)\n",
        "outputs = Dense(10, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "E_DJLfOxyJjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "model = Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "c3OtlM3yyJlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "m-rvJZhQyJoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## complex model with multiple inputs"
      ],
      "metadata": {
        "id": "FRRZFdgcz3wK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import concatenate"
      ],
      "metadata": {
        "id": "DlcviItCyJq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define two sets of inputs\n",
        "inputA = Input(shape=(64,))\n",
        "inputB = Input(shape=(128,))"
      ],
      "metadata": {
        "id": "AxV8BehoyJty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the first branch operates in the first input\n",
        "x = Dense(16, activation='relu')(inputA)\n",
        "x = Dense(8, activation='relu')(x)"
      ],
      "metadata": {
        "id": "FVa9zqCDyJw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the second branch operates on the second input\n",
        "y = Dense(64, activation='relu')(inputB)\n",
        "y = Dense(32, activation='relu')(y)"
      ],
      "metadata": {
        "id": "NEg5FVjMyJzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine the output of the two branches\n",
        "combined = concatenate([x, y])"
      ],
      "metadata": {
        "id": "D-j9eodK0Zx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply a dense layer then a regression prediction on the combined outputs\n",
        "z = Dense(2, activation='relu')(combined)\n",
        "z = Dense(1, activation='linear')(z)"
      ],
      "metadata": {
        "id": "WHMMxXGz0Z0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the model will accept the inputs of the two branches and output a single value\n",
        "model = Model(inputs=[inputA, inputB], outputs=z)"
      ],
      "metadata": {
        "id": "qcXy5V5G0Z3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "CaAq16h70Z-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shared layers\n",
        "\n",
        "helpful when applying the same transformation to multiple inputs\n",
        "\n",
        "you can use shared layers to process 2 different inputs through the same layers and then compare their outputs"
      ],
      "metadata": {
        "id": "rQNVRv5o3lv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import lambda"
      ],
      "metadata": {
        "id": "IHdPWhOW0aCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input layer\n",
        "input = Input(shape=(28,28,1))"
      ],
      "metadata": {
        "id": "1DpfloDd0aE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a shared convolutional base\n",
        "conv_base = Dense(64, activation='relu')"
      ],
      "metadata": {
        "id": "mTy9oaQo0aHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process the input through the shared layer\n",
        "processed_1 = conv_base(input)\n",
        "processed_2 = conv_base(input)"
      ],
      "metadata": {
        "id": "H0Ycw0vo0aKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model using the shared layer\n",
        "\n",
        "model = Model(inputs=input, outputs=[processed_1, processed_2])"
      ],
      "metadata": {
        "id": "CgCctlbS0aNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# practical example : Implementing a complex model"
      ],
      "metadata": {
        "id": "U3NOupLr5AEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.activations import relu, softmax"
      ],
      "metadata": {
        "id": "6vFRZM2z0aQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first input model\n",
        "inputA = Input(shape=(32,32,1))\n",
        "x = Conv2D(32, (3,3), activation=relu)(inputA)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Model(inputs=inputA, outputs=x)\n",
        "# second input model\n",
        "inputB = Input(shape=(32,32,1))\n",
        "y = Conv2D(32, (3,3), activation=relu)(inputB)\n",
        "y = MaxPooling2D((2,2))(y)\n",
        "y = Flatten()(y)\n",
        "y = Model(inputs=inputB, outputs=y)"
      ],
      "metadata": {
        "id": "SlMQc8Tg0aSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine the output of the two branches\n",
        "combined = concatenate([x.output, y.output])"
      ],
      "metadata": {
        "id": "0zcVvpEi0aVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply a FC layer and then a regression prediction on the combined outputs\n",
        "z = Dense(64, activation=relu)(combined)\n",
        "z = Dense(1, activation=softmax)(z)"
      ],
      "metadata": {
        "id": "RynSUfmn0aX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the model will accept the inputs of the two branches and then output a single value\n",
        "model = Model(inputs=[x.input, y.input], outputs=z)"
      ],
      "metadata": {
        "id": "FPV871Wk0aaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subclassing API\n",
        "\n",
        "offers the most flexibility\n",
        "\n",
        "- allows to model custom and dynamic models by subclassing the model class and implementing your own call() method\n",
        "\n",
        "- particularly useful when you need to build models where the forward pass cannot be defined statistically\n",
        "\n",
        "-- we need to subclass the model class and define our layers in the init method\n",
        "\n",
        "\n",
        "\n",
        "-- then we implement the forward pass in the call() method where we explicitly define how the layers are connected and how the data flow through the model"
      ],
      "metadata": {
        "id": "uJPwMK1c6cBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "_LZHKYcO0adH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model by sybclassing\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    # define layers\n",
        "    self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "    self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # define the forward pass\n",
        "    x = self.dense1(inputs)\n",
        "    return self.dense2(x)\n"
      ],
      "metadata": {
        "id": "O7berkN70af5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the model\n",
        "model = MyModel()"
      ],
      "metadata": {
        "id": "A-y4RLSj0ajo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "--Kfp81T0amO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use cases for the subclassing API\n",
        "\n",
        "- models with dynamic architecture. when the architecture of the model needs to be changed dynamically such as certain types of reinforcement learning\n",
        "\n",
        "- custom training loops, when you need more control over the training process\n",
        "\n",
        "- for experimenting with new types of layers or architectures that are not yet available in the the standard keras API\n",
        "\n",
        "\n",
        "- allows the use of dynamic graphs, which means you can change the architecture of the model dynamically during training based on the input data or conditions\n",
        "while in the functional or sequential APIs static graphs are used"
      ],
      "metadata": {
        "id": "WRGP-tx69YPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# implementing a custom training loop\n",
        "\n",
        "- using tf.GradientTape method\n",
        "\n",
        "- provides more flexibility and control over the training process compared to the built in keras.fit method"
      ],
      "metadata": {
        "id": "R0j-gwrk-JDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "# create a dummy training dataset\n",
        "(train_images, train_labels), _ = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape(-1, 28*28).astype('float32') / 255\n",
        "\n",
        "# Flatten and normalize\n",
        "train_labels = train_labels.astype('float32')\n",
        "\n",
        "# create a tf.data dataset for batching\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(32)\n",
        "\n",
        "# custom training loop\n",
        "for epoch in range(epochs):\n",
        "  print(f'epoch {epoch+1}/{epochs}')\n",
        "  for x_batch, y_batch in train_dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # forward pass\n",
        "      y_pred = model(x_batch, training = True)\n",
        "      # compute loss\n",
        "      loss = loss_fn(y_batch, y_pred)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    print(f'loss: {loss.numpy()}')"
      ],
      "metadata": {
        "id": "wCWBXwFt-Ht6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install networkx\n",
        "!pip install matplotlib\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9cOIuCQ78wM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# adding nodes\n",
        "G.add_node('input')\n",
        "G.add_node('Condition check')\n",
        "G.add_node('Path 1 Layer 1')\n",
        "G.add_node('Path 1 Layer 2')\n",
        "G.add_node('Path 2 Layer 1')\n",
        "G.add_node('Path 2 Layer 2')\n",
        "G.add_node('output')\n",
        "\n",
        "# Adding edges for dynamic flow\n",
        "\n",
        "G.add_edges_from([\n",
        "    ('input', 'Condition check'),\n",
        "    ('Condition check', 'Path 1 Layer 1'),\n",
        "    ('Path 1 Layer 1', 'Path 1 Layer 2'),\n",
        "    ('Path 1 Layer 2', 'output'),\n",
        "    ('Condition check', 'Path 2 Layer 1'),\n",
        "    ('Path 2 Layer 1', 'Path 2 Layer 2'),\n",
        "    ('Path 2 Layer 2', 'output') ])\n",
        "\n",
        "\n",
        "# position nodels using a shell layout\n",
        "pos = nx.shell_layout(G)\n",
        "\n",
        "# draw the graph\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw(G, pos, with_labels=True, node_size=3000, node_color='lightblue', font_size=10, font_color='black', edge_color='gray')\n",
        "plt.title('Dynamic Graph Visualization')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tGFvF1z18wPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hyjguk9w8wR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JxU-b1z98wUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z7qlouJD8wWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sos4kxPU8wZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "97N5At4X8wbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mBwB7qW18wdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Opz15I7V8wfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZoJcptu8wiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HC9n9_UP8wkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B6Tdb3sD8wmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ejMGrYQ88wpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vtFsi8oa8wrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O5kP5twN8wth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7yyTCkIZ8wvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cVQ7pHcH8w1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KmNC5TGp8w37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gwUkmJS18w6a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}